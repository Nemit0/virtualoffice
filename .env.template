OPENAI_API_KEY =
OPENAI_API_KEY2 =
OPENROUTER_API_KEY =
VDOS_USE_OPENROUTER = false
VDOS_LOCALE = ko

# API Provider Selection
# Choose which API endpoint to use for LLM calls
# Options: "auto" (default), "openai_key1", "openai_key2", "azure"
# - "auto": Automatically selects based on free tier limits (key1 → key2 → azure)
# - "openai_key1": Always use OPENAI_API_KEY
# - "openai_key2": Always use OPENAI_API_KEY2
# - "azure": Always use Azure OpenAI
VDOS_API_PROVIDER = auto

# Experimental: Override all model selections with a fixed model
# Set FIX_ALL_GPT_MODEL=true to enable, then specify model in FIXED_MODEL
# Example: FIXED_MODEL=gpt-4o or gpt-4o-mini
FIX_ALL_GPT_MODEL = false
FIXED_MODEL = gpt-4o

AZURE_AREA =
AZURE_OPENAI_API_KEY =
AZURE_OPENAI_ENDPOINT =

# Server Configuration (used by briefcase dev)
VDOS_CHAT_HOST = 127.0.0.1
VDOS_CHAT_PORT = 8001
VDOS_EMAIL_HOST = 127.0.0.1
VDOS_EMAIL_PORT = 8000
VDOS_SIM_HOST = 127.0.0.1
VDOS_SIM_PORT = 8015